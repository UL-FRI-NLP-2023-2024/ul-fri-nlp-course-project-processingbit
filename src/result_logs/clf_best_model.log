Model: meta-llama/Meta-Llama-3-8B-Instruct
DatasetDict({
    train: Dataset({
        features: ['index', 'text', 'labels'],
        num_rows: 543
    })
    validation: Dataset({
        features: ['index', 'text', 'labels'],
        num_rows: 181
    })
    test: Dataset({
        features: ['index', 'text', 'labels'],
        num_rows: 181
    })
})
Classification Report:
                   precision    recall  f1-score   support

     Deliberation       0.82      0.82      0.82        45
Imaginative Entry       1.00      0.83      0.91         6
            Other       0.67      1.00      0.80         2
        Procedure       0.83      0.77      0.80        13
          Seminar       0.94      0.98      0.96        89
           Social       0.93      0.81      0.87        16
               UX       0.89      0.80      0.84        10

         accuracy                           0.90       181
        macro avg       0.87      0.86      0.86       181
     weighted avg       0.90      0.90      0.89       181

Accuracy: 0.90
Precision: 0.90
Recall: 0.90
F1 Score: 0.89
