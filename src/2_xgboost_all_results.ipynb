{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gensim.downloader as api\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\") # Download pretrained model\n",
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['r2_discussion_type', 'r2_dialogic_spell', 'r2_uptake', 'r2_question', 'from_pivot', 'to_pivot']\n",
    "DATA_SAVE_PATH = \"./cleaned_data/to_pivot_data_all.csv\"\n",
    "TARGET_COLUMN = target_columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization, lowercasing, removing stopwords, etc.\n",
    "    tokens = [word.lower() for word in nltk.word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data = pd.read_csv(DATA_SAVE_PATH)\n",
    "data['message'] = data['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>book_id</th>\n",
       "      <th>bookclub</th>\n",
       "      <th>chat_crew</th>\n",
       "      <th>pseudonym</th>\n",
       "      <th>is_answer</th>\n",
       "      <th>page</th>\n",
       "      <th>response_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.036086</td>\n",
       "      <td>0.052419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074865</td>\n",
       "      <td>0.092050</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.029422</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168975</td>\n",
       "      <td>0.174576</td>\n",
       "      <td>-0.199167</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>0.081092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065781</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.084817</td>\n",
       "      <td>-0.059670</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>-0.003281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277774</td>\n",
       "      <td>-0.101370</td>\n",
       "      <td>-0.169284</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   course  book_id  bookclub  chat_crew  pseudonym  is_answer  page  \\\n",
       "0       1      260         1       True         46      False    10   \n",
       "1       1      260         1       True         46      False    10   \n",
       "2       1      260         1       True         46      False    10   \n",
       "3       1      260         1       True         48      False    10   \n",
       "4       1      260         1       True         48      False    10   \n",
       "\n",
       "   response_number         0         1  ...       296       297       298  \\\n",
       "0              3.1 -0.036086  0.052419  ...  0.074865  0.092050 -0.000639   \n",
       "1              3.1 -0.012513  0.045208  ...  0.018545 -0.095000 -0.009200   \n",
       "2              3.1  0.018834  0.003210  ...  0.168975  0.174576 -0.199167   \n",
       "3              3.1  0.010507  0.081092  ...  0.065781  0.009381  0.084817   \n",
       "4              3.1  0.008774 -0.003281  ...  0.277774 -0.101370 -0.169284   \n",
       "\n",
       "        299    year  month   day  hour  minute  second  \n",
       "0  0.029422  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "1 -0.000744  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "2  0.009118  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "3 -0.059670  2020.0   10.0  27.0  17.0    58.0     0.0  \n",
       "4  0.017724  2020.0   10.0  27.0  17.0    58.0     0.0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'ashely' not in vocabulary\n",
      "Word 'orgininally' not in vocabulary\n",
      "Word 'uwgyeu' not in vocabulary\n",
      "Word 'kyra' not in vocabulary\n",
      "Word 'emilie' not in vocabulary\n",
      "Word 'emilie' not in vocabulary\n",
      "Word 'kyra' not in vocabulary\n",
      "Word 'kyra' not in vocabulary\n",
      "Word 'darla' not in vocabulary\n",
      "Word 'experien' not in vocabulary\n",
      "Word 'amswered' not in vocabulary\n",
      "Word 'sentemce' not in vocabulary\n",
      "Word 'acce' not in vocabulary\n",
      "Word 'lillian' not in vocabulary\n",
      "Word 'semibarbaric' not in vocabulary\n",
      "Word 'semibarbaric' not in vocabulary\n",
      "Word 'barberous' not in vocabulary\n",
      "Word 'discourager' not in vocabulary\n",
      "Word 'alexandrea' not in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Convert text data into numerical vectors using FastText word embeddings\n",
    "def get_embedding(text):\n",
    "    # Initialize an empty vector\n",
    "    vector = np.zeros(300)\n",
    "    # Iterate over each word in the text\n",
    "    for word in text.split():\n",
    "        # If the word is in the FastText vocabulary, add its embedding to the vector\n",
    "        if word in fasttext_model:\n",
    "            vector += fasttext_model[word]\n",
    "        else:\n",
    "            print(f\"Word '{word}' not in vocabulary\")\n",
    "    # Return the vector\n",
    "    return vector\n",
    "\n",
    "mess_embeddings = pd.DataFrame(data['message'].apply(get_embedding).tolist())\n",
    "\n",
    "data = pd.concat([data, mess_embeddings], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[TARGET_COLUMN]\n",
    "data['course'] = LabelEncoder().fit_transform(data['course'])\n",
    "data['book_id'] = data['book_id'].astype(int)\n",
    "data['bookclub'] = data['bookclub'].astype(int)\n",
    "data['chat_crew'] = data['chat_crew'].astype(bool)\n",
    "data['pseudonym'] = LabelEncoder().fit_transform(data['pseudonym'])\n",
    "\n",
    "data['time'] = pd.to_datetime(data['time'], errors='coerce')\n",
    "\n",
    "data['year'] = data['time'].dt.year\n",
    "data['month'] = data['time'].dt.month\n",
    "data['day'] = data['time'].dt.day\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "data['second'] = data['time'].dt.second\n",
    "\n",
    "data['page'] = data['page'].fillna(0).astype(int)\n",
    "data['response_number'] = data['response_number'].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['time', 'message', TARGET_COLUMN], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>book_id</th>\n",
       "      <th>bookclub</th>\n",
       "      <th>chat_crew</th>\n",
       "      <th>pseudonym</th>\n",
       "      <th>is_answer</th>\n",
       "      <th>page</th>\n",
       "      <th>response_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.036086</td>\n",
       "      <td>0.052419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074865</td>\n",
       "      <td>0.092050</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.029422</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168975</td>\n",
       "      <td>0.174576</td>\n",
       "      <td>-0.199167</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>0.081092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065781</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.084817</td>\n",
       "      <td>-0.059670</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>-0.003281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277774</td>\n",
       "      <td>-0.101370</td>\n",
       "      <td>-0.169284</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   course  book_id  bookclub  chat_crew  pseudonym  is_answer  page  \\\n",
       "0       1      260         1       True         46      False    10   \n",
       "1       1      260         1       True         46      False    10   \n",
       "2       1      260         1       True         46      False    10   \n",
       "3       1      260         1       True         48      False    10   \n",
       "4       1      260         1       True         48      False    10   \n",
       "\n",
       "   response_number         0         1  ...       296       297       298  \\\n",
       "0              3.1 -0.036086  0.052419  ...  0.074865  0.092050 -0.000639   \n",
       "1              3.1 -0.012513  0.045208  ...  0.018545 -0.095000 -0.009200   \n",
       "2              3.1  0.018834  0.003210  ...  0.168975  0.174576 -0.199167   \n",
       "3              3.1  0.010507  0.081092  ...  0.065781  0.009381  0.084817   \n",
       "4              3.1  0.008774 -0.003281  ...  0.277774 -0.101370 -0.169284   \n",
       "\n",
       "        299    year  month   day  hour  minute  second  \n",
       "0  0.029422  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "1 -0.000744  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "2  0.009118  2020.0   10.0  20.0  17.0     6.0     0.0  \n",
       "3 -0.059670  2020.0   10.0  27.0  17.0    58.0     0.0  \n",
       "4  0.017724  2020.0   10.0  27.0  17.0    58.0     0.0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=5,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=5,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=5,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made for -> from_pivot\n",
      "Accuracy: 0.9193548387096774\n",
      "Precision: 0.8452133194588969\n",
      "Recall: 0.9193548387096774\n",
      "F1: 0.8807264841420439\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       Deliberation       0.00      0.00      0.00         2\n",
      "  Imaginative Entry       0.00      0.00      0.00         1\n",
      "            Seminar       0.00      0.00      0.00         4\n",
      "Social/Procedure/UX       0.00      0.00      0.00         3\n",
      "                nan       0.92      1.00      0.96       114\n",
      "\n",
      "           accuracy                           0.92       124\n",
      "          macro avg       0.18      0.20      0.19       124\n",
      "       weighted avg       0.85      0.92      0.88       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Predictions made for -> {TARGET_COLUMN}')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Convert label_encoder.classes_ to strings\n",
    "target_names = [str(label) for label in label_encoder.classes_]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores by Target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Class         | Precision |  Recall  | F1-Score |\n",
    "|---------------------|-----------|----------|----------|\n",
    "| Deliberation        |   0.82    |   0.50   |   0.62   |\n",
    "| Imaginative Entry   |   0.00    |   0.00   |   0.00   |\n",
    "| Other               |   0.00    |   0.00   |   0.00   |\n",
    "| Procedure           |   0.75    |   0.67   |   0.71   |\n",
    "| Seminar             |   0.76    |   0.97   |   0.85   |\n",
    "| Social              |   0.82    |   0.64   |   0.72   |\n",
    "| UX                  |   0.50    |   0.30   |   0.37   |\n",
    "\n",
    "- **Accuracy**: 0.7419\n",
    "- **Macro Avg Precision**: 0.52\n",
    "- **Macro Avg Recall**: 0.44\n",
    "- **Macro Avg F1-Score**: 0.47\n",
    "- **Weighted Avg Precision**: 0.71\n",
    "- **Weighted Avg Recall**: 0.74\n",
    "- **Weighted Avg F1-Score**: 0.71\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogic Spell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Class   | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "|     1   |   0.65    |  0.70  |   0.67   |    40   |\n",
    "|     2   |   0.59    |  0.62  |   0.60   |    26   |\n",
    "|     3  |   0.57    |  0.31  |   0.40   |    13   |\n",
    "|     4  |   0.00    |  0.00  |   0.00   |    6    |\n",
    "|     5  |   1.00    |  0.33  |   0.50   |    3    |\n",
    "|     6   |   0.00    |  0.00  |   0.00   |    2    |\n",
    "|     7   |   0.67    |  1.00  |   0.80   |    4    |\n",
    "|    nan    |   0.55    |  0.73  |   0.63   |    30   |\n",
    "\n",
    "- **Accuracy**: 0.6048\n",
    "- **Macro Avg Precision**: 0.50\n",
    "- **Macro Avg Recall**: 0.46\n",
    "- **Macro Avg F1-Score**: 0.45\n",
    "- **Weighted Avg Precision**: 0.57\n",
    "- **Weighted Avg Recall**: 0.60\n",
    "- **Weighted Avg F1-Score**: 0.58\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uptake"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Class   | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "|   Affirm  |    0.50   |  0.46  |   0.48   |    28   |\n",
    "|  Clarify  |    0.33   |  0.09  |   0.14   |    11   |\n",
    "|  Disagree |    0.00   |  0.00  |   0.00   |    2    |\n",
    "| Elaborate |    0.27   |  0.18  |   0.22   |    22   |\n",
    "|   Filler  |    0.50   |  0.25  |   0.33   |    12   |\n",
    "|    nan    |    0.53   |  0.80  |   0.63   |    49   |\n",
    "\n",
    "- **Accuracy**: 0.4839\n",
    "- **Macro Avg Precision**: 0.35\n",
    "- **Macro Avg Recall**: 0.30\n",
    "- **Macro Avg F1-Score**: 0.30\n",
    "- **Weighted Avg Precision**: 0.45\n",
    "- **Weighted Avg Recall**: 0.48\n",
    "- **Weighted Avg F1-Score**: 0.44\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Class   | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "|   C-HOT   |    0.00   |  0.00  |   0.00   |    4    |\n",
    "|   C-LOT   |    0.00   |  0.00  |   0.00   |    9    |\n",
    "|   O-HOT   |    1.00   |  0.50  |   0.67   |    2    |\n",
    "|   O-LOT   |    0.00   |  0.00  |   0.00   |    2    |\n",
    "|    nan    |    0.87   |  1.00  |   0.93   |   107   |\n",
    "\n",
    "- **Accuracy**: 0.871\n",
    "- **Macro Avg Precision**: 0.37\n",
    "- **Macro Avg Recall**: 0.30\n",
    "- **Macro Avg F1-Score**: 0.32\n",
    "- **Weighted Avg Precision**: 0.767\n",
    "- **Weighted Avg Recall**: 0.871\n",
    "- **Weighted Avg F1-Score**: 0.814\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Class        | Precision | Recall | F1-Score | Support |\n",
    "|---------------------|-----------|--------|----------|---------|\n",
    "|     Deliberation   |    0.00   |  0.00  |   0.00   |    2    |\n",
    "|  Imaginative Entry |    0.00   |  0.00  |   0.00   |    1    |\n",
    "|       Seminar      |    0.00   |  0.00  |   0.00   |    4    |\n",
    "| Social/Procedure/UX|    0.00   |  0.00  |   0.00   |    3    |\n",
    "|         nan         |    0.92   |  1.00  |   0.96   |   114   |\n",
    "\n",
    "- **Accuracy**: 0.919\n",
    "- **Macro Avg Precision**: 0.18\n",
    "- **Macro Avg Recall**: 0.20\n",
    "- **Macro Avg F1-Score**: 0.19\n",
    "- **Weighted Avg Precision**: 0.845\n",
    "- **Weighted Avg Recall**: 0.919\n",
    "- **Weighted Avg F1-Score**: 0.881\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Class        | Precision | Recall | F1-Score | Support |\n",
    "|---------------------|-----------|--------|----------|---------|\n",
    "|     Deliberation   |    0.00   |  0.00  |   0.00   |    2    |\n",
    "|  Imaginative Entry |    0.00   |  0.00  |   0.00   |    1    |\n",
    "|       Seminar      |    0.00   |  0.00  |   0.00   |    4    |\n",
    "| Social/Procedure/UX|    0.00   |  0.00  |   0.00   |    3    |\n",
    "|         nan         |    0.92   |  1.00  |   0.96   |   114   |\n",
    "\n",
    "- **Accuracy**: 0.919\n",
    "- **Macro Avg Precision**: 0.18\n",
    "- **Macro Avg Recall**: 0.20\n",
    "- **Macro Avg F1-Score**: 0.19\n",
    "- **Weighted Avg Precision**: 0.845\n",
    "- **Weighted Avg Recall**: 0.919\n",
    "- **Weighted Avg F1-Score**: 0.881\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
