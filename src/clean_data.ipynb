{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/dataset1.csv')\n",
    "# Dropping topic because it has only one value. It might be usefull if we had more data\n",
    "df = df.drop(columns=['Old Code Book', 'Memo', 'Chat0CREW1B', 'Chat0CREW1', 'Response Number', 'Message Time', 'CollapsR2DiscussionTypeInterpNothers', 'R2DiscussionTypeInterpNothers'])\n",
    "df.columns = [''.join([word[0].upper() + word[1:] for word in col.split()]) for col in df.columns]\n",
    "df.columns = [col.replace(' ', '') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Course', 'BookID', 'Topic', 'Bookclub', 'Pseudonym', 'Message',\n",
       "       'IsAnswer', 'Page', 'R1DiscussionType', 'R2DiscussionType',\n",
       "       'R1DialogicSpell', 'BinaryR1DialogicSpell', 'R1Uptake',\n",
       "       'BinaryR1Uptake', 'R2DialogicSpell', 'BinaryR2DialogicSpell',\n",
       "       'R2Uptake', 'BinaryR2Uptake', 'Pseudonym.1', 'Message.1', 'Bookclub.1',\n",
       "       'R1Question', 'R2Question', 'R1Pivot', 'R2Pivot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If R1 has a value and R2 does not should we trust R1? Let us look at some of the examples to see if this is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column R2DialogicSpell has NaN where R1DialogicSpell has a value\n",
      "    R1DialogicSpell R2DialogicSpell  BinaryR2Uptake\n",
      "240                             NaN               0\n",
      "261           Begin             NaN               0\n",
      "268                             NaN               0\n",
      "273                             NaN               1\n",
      "274                             NaN               0\n",
      "                                               Message\n",
      "240  she was smiling by the end and the book told m...\n",
      "261  As for the second question I believe that the ...\n",
      "268               Hey guys I got through the next page\n",
      "273                            I know live without him\n",
      "274       im just back at the screen we were at before\n",
      "Column BinaryR2DialogicSpell has NaN where BinaryR1DialogicSpell has a value\n",
      "     BinaryR1DialogicSpell  BinaryR2DialogicSpell  BinaryR2Uptake\n",
      "315                      1                    NaN               0\n",
      "316                      1                    NaN               0\n",
      "                                               Message\n",
      "315  I think she sends him to the door with the tig...\n",
      "316                             Ha, I meant successor.\n",
      "Column R2Uptake has NaN where R1Uptake has a value\n",
      "      R1Uptake R2Uptake  BinaryR2Uptake\n",
      "321  Elaborate      NaN               0\n",
      "322     Affirm      NaN               0\n",
      "596     Prompt      NaN               0\n",
      "                                               Message\n",
      "321  But I think he would also revel in the fact th...\n",
      "322  Just realized I never answered the second ques...\n",
      "596  I certainly hoped that she was steering her lo...\n",
      "Column R2Question has NaN where R1Question has a value\n",
      "    R1Question R2Question  BinaryR2Uptake\n",
      "272      C-LOT        NaN               1\n",
      "                                 Message\n",
      "272  Did you guys get the final question\n",
      "Column R2Pivot has NaN where R1Pivot has a value\n",
      "                                 R1Pivot R2Pivot  BinaryR2Uptake\n",
      "208  Deliberation to Social/Procedure/UX     NaN               1\n",
      "209  Social/Procedure/UX to Deliberation     NaN               1\n",
      "226              Seminar to Deliberation     NaN               1\n",
      "227              Deliberation to Seminar     NaN               1\n",
      "233  Deliberation to Social/Procedure/UX     NaN               1\n",
      "                                               Message\n",
      "208                                             Great!\n",
      "209  Looks good. I think to mark our assignment don...\n",
      "226  I agree that the princess could just banish th...\n",
      "227  I don't think we have to agree on a single end...\n",
      "233  So the top is for chatting and the bottom is f...\n"
     ]
    }
   ],
   "source": [
    "# Identify the columns that start with R1 and R2 and have the same suffix\n",
    "r1_columns = [col for col in df.columns if col.startswith('R1') or col.startswith('BinaryR1')]\n",
    "r2_columns = [col for col in df.columns if col.startswith('R2') or col.startswith('BinaryR2')]\n",
    "\n",
    "# Make sure that the suffixes match\n",
    "matched_columns = [(r1, r2) for r1 in r1_columns for r2 in r2_columns if r1[2:] == r2[2:] or (r1[9:] == r2[9:] and r1.startswith('Binary') and r2.startswith('Binary'))]\n",
    "matched_columns\n",
    "#\n",
    "## Iterate over these pairs of columns\n",
    "for r1_col, r2_col in matched_columns:\n",
    "    # Find rows where the R2 version has NaN and the R1 version has a value\n",
    "    condition = df[r2_col].isna() & df[r1_col].notna()\n",
    "    if condition.any():# and \"Dialogic\" not in r1_col:\n",
    "        print(f'Column {r2_col} has NaN where {r1_col} has a value')\n",
    "        print(df.loc[condition, [r1_col, r2_col, 'BinaryR2Uptake']].head())\n",
    "        print(df.loc[condition, ['Message']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to not be needed because all cases it is hard for me to tell which one is correct R1 or R2. Both answers seem valid so I will keep it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=r1_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I remove duplicate columns and check if there are any values that are nan in the one I keep and not the other. In this case there were none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot1_columns = [col for col in df.columns if col.endswith('.1')]\n",
    "original_columns = [col.rstrip('.1') for col in dot1_columns if col.rstrip('.1') in df.columns]\n",
    "\n",
    "# For each pair of columns, if one column has a value and the other does not, keep the value\n",
    "for orig_col, dot1_col in zip(original_columns, dot1_columns):\n",
    "    if (df[orig_col].isna() & df[dot1_col].notna()).any():\n",
    "        print(f'Column {orig_col} has a value where {dot1_col} has NaN')\n",
    "\n",
    "# Remove the .1 columns\n",
    "df = df.drop(columns=dot1_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 discussion type columns. The collapsed one was apparently used for visualisation according to the given paper so it is not needed. This leaves us with R2DiscussionTypeInterpNothers and R2DiscussionType. The first seems to use interpreatation instead of seminar and that is not in the codebook so we will use the first column. I will now look at the unique values of the columns and see their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3957307060755337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230515/412174125.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(counts[0]/counts.sum())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "R2Uptake\n",
       "NaN          241\n",
       "Affirm       140\n",
       "Elaborate    107\n",
       "Filler        61\n",
       "Clarify       50\n",
       "Disagree      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df['R2Uptake'].value_counts(dropna=False)\n",
    "print(counts[0]/counts.sum())\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are not prompt or respond examples that can be found in the codebook. Also most are NaN which makes sense since maybe those are not uptakes. ALso NaNs are 40% of the data so we must achieve accuracy higher than 40 to have results better than just guessing NaN each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2Question\n",
       "NaN              525\n",
       "C-LOT             36\n",
       "C-HOT             22\n",
       "O-HOT             11\n",
       "O-LOT              8\n",
       "C-LOT, C-LOT       3\n",
       "O-COT              1\n",
       "C-HOT, C-HOT       1\n",
       "O-HOT, C-LOT       1\n",
       "C-LOT? C-HOT?      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['R2Question'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have few samples compared to the total samples size that have a Question category. Also we have one sample with 2 labels. Which is likely not enough for our model to learn anything. This can probably be dropped when training and the ones that are C-LOT C-LOT can be converted just to a single C-LOT. Another options is to split the sentence somehow and classify separately and then combine the labels. This seems like a good idea and I might try it. For the C-LOT? C-HOT? it seems the expert is unsure what to write so we will either drop it or trust R1 which chose for that sample C-LOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2Pivot\n",
       "NaN                                           562\n",
       "Seminar to Social/Procedure/UX                 10\n",
       "Social/Procedure/UX to Seminar                  8\n",
       "Seminar to Deliberation                         7\n",
       "Deliberation to Social/Procedure/UX             4\n",
       "Social/Procedure/UX to Social/Procedure/UX      4\n",
       "Social/Procedure/UX to Deliberation             3\n",
       "Deliberation to Seminar                         3\n",
       "Seminar to Imaginative entry                    2\n",
       "Imaginative entry to Seminar                    2\n",
       "Seminar to Imaginative                          1\n",
       "Imaginative to Seminar                          1\n",
       "Delibration to Seminar                          1\n",
       "Deliberationa to Seminar                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['R2Pivot'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "value_counts = df['R2Pivot'].value_counts(dropna=True)\n",
    "total = value_counts.sum()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding history here bofore I drop more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Message'])\n",
    "\n",
    "# Get the feature names and IDF values\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "# Create a DataFrame with feature names and IDF values\n",
    "idf_df = pd.DataFrame({'feature': feature_names, 'idf': idf_values})\n",
    "\n",
    "# Sort the DataFrame by IDF values and get the top 100 features\n",
    "idf_df = idf_df.sort_values('idf')\n",
    "top_features = idf_df.head(50)['feature'].values\n",
    "\n",
    "# Get the indices of the top features\n",
    "top_feature_indices = [list(feature_names).index(feature) for feature in top_features]\n",
    "\n",
    "# Get the TF-IDF values of the top features for each document\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix[:, top_feature_indices].toarray(), columns=top_features)\n",
    "\n",
    "# Concatenate the original DataFrame with the TF-IDF DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for the previous messages\n",
    "#df['PrevMessage1'] = ''\n",
    "#df['PrevMessage2'] = ''\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "#for i in range(1, len(df)):\n",
    "    # Check if the previous row has the same 'BookID', 'Bookclub', and 'Course'\n",
    "    #if (df.loc[i, 'BookID'] == df.loc[i-1, 'BookID'] and\n",
    "    #    df.loc[i, 'Bookclub'] == df.loc[i-1, 'Bookclub'] and\n",
    "    #    df.loc[i, 'Course'] == df.loc[i-1, 'Course']):\n",
    "    #    # If it does, add the previous message to 'PrevMessage1'\n",
    "    #    df.loc[i, 'PrevMessage1'] = df.loc[i-1, 'Message']\n",
    "        \n",
    "        # If there is more than one previous row and it also has the same 'BookID', 'Bookclub', and 'Course'\n",
    "        #if i > 1 and (df.loc[i, 'BookID'] == df.loc[i-2, 'BookID'] and\n",
    "        #              df.loc[i, 'Bookclub'] == df.loc[i-2, 'Bookclub'] and\n",
    "        #              df.loc[i, 'Course'] == df.loc[i-2, 'Course']):\n",
    "        #    # Add the second previous message to 'PrevMessage2'\n",
    "        #    df.loc[i, 'PrevMessage2'] = df.loc[i-2, 'Message']\n",
    "\n",
    "# If the first row has no previous messages, fill 'PrevMessage1' and 'PrevMessage2' with empty strings\n",
    "#df.loc[0, ['PrevMessage1']] = '' #, 'PrevMessage2']] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this one we don't have many samples separately but maybe we can make a binary classifier and just take the previous and next category. The classifier will just say pivot yes or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsAnswer\n",
       "No     501\n",
       "NaN    106\n",
       "         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IsAnswer'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Answer is either No or NaN. The NaN value does not mean it is an answer. I looked at the fields that were labelled NaN and they can also be a greeting which is not an answer or a statement which is not always an answer. Because of this I believe this column is not useful for training and I will drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['IsAnswer'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BookID\n",
       "260    421\n",
       "261    188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BookID'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bookclub\n",
       "Book Club One      275\n",
       "Book Club Four     192\n",
       "Book Club Two       94\n",
       "Book Club Three     30\n",
       "Book Club Five      18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Bookclub'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BookID, Page and Bookclub I am unsure if they will be usefull in the end. My reasoning is because we want to generalise and what if we add a Bookclub 6 and if the model has never seen it. Or if we add a new book but the model has learned something about the specific books 260 and 261. Because of this I believe it is better to drop these columns. I was considering maybe they could be used for ids of different discussions since only a club or only a book is not enough to determine a discussion and we want to classify sentences in separate probably. If we want context we can try to use history instead of these ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['BookID', 'Bookclub', 'Page', 'Course', 'Topic'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social/Procedure/UX to Seminar\n",
      "Social Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Seminar\n",
      "Social/Procedure/UX to Seminar\n",
      "Seminar Procedure\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Deliberation to Social/Procedure/UX\n",
      "Deliberation Social\n",
      "Social/Procedure/UX to Social/Procedure/UX\n",
      "Social Procedure\n",
      "Social/Procedure/UX to Seminar\n",
      "Procedure Seminar\n",
      "Seminar to Imaginative entry\n",
      "Seminar Imaginative entry\n",
      "Imaginative entry to Seminar\n",
      "Imaginative entry Seminar\n",
      "Seminar to Imaginative entry\n",
      "Seminar Imaginative entry\n",
      "Imaginative entry to Seminar\n",
      "Imaginative entry Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Procedure\n",
      "Social/Procedure/UX to Social/Procedure/UX\n",
      "Procedure Social\n",
      "Social/Procedure/UX to Deliberation\n",
      "Social Deliberation\n",
      "Deliberation to Seminar\n",
      "Deliberation Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Procedure\n",
      "Social/Procedure/UX to Seminar\n",
      "Procedure Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Procedure\n",
      "Social/Procedure/UX to Seminar\n",
      "Procedure Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Social\n",
      "Social/Procedure/UX to Deliberation\n",
      "Deliberation Deliberation\n",
      "Deliberation to Social/Procedure/UX\n",
      "Deliberation Social\n",
      "Social/Procedure/UX to Seminar\n",
      "Social Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Social\n",
      "Social/Procedure/UX to Seminar\n",
      "Social Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar UX\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Social\n",
      "Seminar to Deliberation\n",
      "Seminar Seminar, Deliberation\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Deliberation to Seminar\n",
      "Deliberation Seminar\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Seminar to Social/Procedure/UX\n",
      "Deliberation Seminar\n",
      "Social/Procedure/UX to Social/Procedure/UX\n",
      "Social Procedure\n",
      "Social/Procedure/UX to Social/Procedure/UX\n",
      "Procedure Social\n",
      "Deliberation to Seminar\n",
      "Social Seminar\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Deliberation to Social/Procedure/UX\n",
      "Deliberation Social\n",
      "Social/Procedure/UX to Deliberation\n",
      "Procedure Deliberation\n",
      "Deliberation to Social/Procedure/UX\n",
      "Deliberation Procedure\n",
      "Social/Procedure/UX to Seminar\n",
      "Social Seminar\n",
      "Seminar to Imaginative\n",
      "Seminar Imaginative\n",
      "Imaginative to Seminar\n",
      "Imaginative Seminar\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Delibration to Seminar\n",
      "Deliberation Seminar\n",
      "Seminar to Deliberation\n",
      "Seminar Deliberation\n",
      "Deliberationa to Seminar\n",
      "Deliberation Seminar\n",
      "Seminar to Social/Procedure/UX\n",
      "Seminar Social\n"
     ]
    }
   ],
   "source": [
    "# Select all rows where 'R2Pivot' is not NaN\n",
    "non_nan_rows = df[df['R2Pivot'].notna()]\n",
    "\n",
    "# Get the indices of the non-NaN rows\n",
    "indices = non_nan_rows.index\n",
    "\n",
    "# Print the current 'R2DiscussionType' for these rows and the 'R2DiscussionType' from the previous row in the original DataFrame\n",
    "res = zip(non_nan_rows['R2DiscussionType'], df.loc[indices - 1, 'R2DiscussionType'] if indices[0] > 0 else None)\n",
    "\n",
    "for idx, (next, prev) in enumerate(res):\n",
    "    print(non_nan_rows.iloc[idx]['R2Pivot'])\n",
    "    print(prev, next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODELS = {\n",
    "    'bert': 'bert-base-uncased',\n",
    "    'roberta': 'roberta-base',\n",
    "    'xlnet': 'xlnet-large-cased',\n",
    "    'xlm': 'xlm-mlm-en-2048',\n",
    "    'distilbert': 'distilbert-base-uncased',\n",
    "    'albert':'albert-base-v2'\n",
    "}\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    #'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    #'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    #'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    #'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    #'albert':(AlbertForSequenceClassification,AlbertTokenizer, AlbertConfig)\n",
    "}\n",
    "\n",
    "MODEL_TYPE = 'bert'\n",
    "PRETRAINED_MODEL_NAME = PRETRAINED_MODELS[MODEL_TYPE]\n",
    "\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[MODEL_TYPE]\n",
    "\n",
    "TRUNCATION = True\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2columns = [col for col in df.columns if 'R2' in col]\n",
    "X = df.drop(columns=r2columns).fillna('')\n",
    "y = df['R2Uptake'].fillna('None')\n",
    "\n",
    "X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_tmp, test_size=0.2, random_state=42, stratify=y_train_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2UptakeDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_length):\n",
    "        self.X = X.values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        # Fit the label binarizer and transform the labels into one-hot encoded format\n",
    "        self.labels = enc.transform(y.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Encode the utterance using the provided tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.X[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_length,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=TRUNCATION,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # Convert the list of strings into a one-hot encoded format\n",
    "        label = self.labels[idx]  # This should now be a binary vector instead of a list of strings\n",
    "\n",
    "        # Return the encoding and the label\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(df['R2Uptake'].unique())\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "class StratifiedSampler(Sampler):\n",
    "    def __init__(self, class_vector, batch_size):\n",
    "        self.n_splits = int(class_vector.size(0) / batch_size)\n",
    "        self.class_vector = class_vector\n",
    "\n",
    "    def gen_sample_array(self):\n",
    "        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n",
    "        X = torch.randn(self.class_vector.size(0),2).numpy()\n",
    "        y = self.class_vector.numpy()\n",
    "        s.get_n_splits(X, y)\n",
    "\n",
    "        train_index, test_index = next(s.split(X, y))\n",
    "        return np.hstack([train_index, test_index])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.gen_sample_array())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2Uptake\n",
      "None         154\n",
      "Affirm        90\n",
      "Elaborate     68\n",
      "Filler        39\n",
      "Clarify       32\n",
      "Disagree       6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_texts = X_train.apply(lambda x: ('|'.join(x.astype(str))).replace('0.0', ''), axis=1)\n",
    "train_labels = y_train\n",
    "\n",
    "val_texts = X_val.apply(lambda x: ('|'.join(x.astype(str))).replace('0.0', ''), axis=1)\n",
    "val_labels = y_val\n",
    "\n",
    "test_texts = X_test.apply(lambda x: ('|'.join(x.astype(str))).replace('0.0', ''), axis=1)\n",
    "test_labels = y_test\n",
    "\n",
    "longest_train_data = train_texts[train_texts.str.len().idxmax()]\n",
    "max_length = min(2 ** (len(tokenizer.tokenize(longest_train_data))-1).bit_length(), 512)\n",
    "print(train_labels.value_counts())\n",
    "\n",
    "train_data = R2UptakeDataset(train_texts, train_labels, tokenizer, max_length=max_length)\n",
    "val_data = R2UptakeDataset(val_texts, val_labels, tokenizer, max_length=max_length)\n",
    "test_data = R2UptakeDataset(test_texts, test_labels, tokenizer, max_length=max_length)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_labels)\n",
    "val_labels_encoded = le.transform(val_labels)\n",
    "\n",
    "trainSampler = StratifiedSampler(torch.tensor(train_labels_encoded), BATCH_SIZE)\n",
    "valSampler = StratifiedSampler(torch.tensor(val_labels_encoded), BATCH_SIZE)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=trainSampler)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, sampler=valSampler)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cheryl Diaz',\n",
       " \"We can continue to discuss individually, or if you want to try writing collaboratively at the same time, please suggest a time. I'm available any evening this week starting at 6 p.m. I'll keep tabs on here from now on to see if you want to do that. Thanks, Robyn\",\n",
       " '4619300045485831',\n",
       " '0.2262973847672804',\n",
       " '6433665813448955',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.16672712179392618',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.17336175701849443',\n",
       " '',\n",
       " '',\n",
       " '0.17698922476304443',\n",
       " '',\n",
       " '8964028075721846',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '9427971979086341',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '9872370817676032',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.10272620462479903',\n",
       " '0.1039798308341429',\n",
       " '',\n",
       " '',\n",
       " '0.10737538149340177',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts.iloc[3].split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filler'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#HIDDEN_WEIGHTS = 768\n",
    "HIDDEN_WEIGHTS = 256\n",
    "DROPOUT = 0.3\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.l1 = model_class.from_pretrained(pretrained_model_name, num_labels=self.num_labels)\n",
    "        self.pre_classifier = torch.nn.Linear(self.num_labels, HIDDEN_WEIGHTS)\n",
    "        self.dropout = torch.nn.Dropout(DROPOUT)\n",
    "        self.classifier = torch.nn.Linear(HIDDEN_WEIGHTS, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = output.view(-1, self.num_labels)  # Reshape the output\n",
    "        return output\n",
    "\n",
    "model = BERTClass(PRETRAINED_MODEL_NAME, num_labels)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay/EMAI/Ljublajna/NLP/ul-fri-nlp-course-project-processingbit/.venv/lib/python3.11/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_dataloader):\n",
    "    val_targets = []\n",
    "    val_outputs = []\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_targets.extend(labels.cpu().detach().numpy().tolist())\n",
    "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            \n",
    "\n",
    "    val_loss /= len(valid_dataloader)\n",
    "    \n",
    "    return val_loss, val_targets, val_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "        attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs, train_dataloader, valid_dataloader, model, optimizer, best_model_path = \"./\", patience=1):\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    num_not_improved = 0\n",
    "    for epoch in range(1, num_epochs):\n",
    "        print()\n",
    "        print(\"#################### Epoch {}: Training Start    ####################\".format(epoch))\n",
    "        train_loss = train(model, train_dataloader)\n",
    "        print('#################### Epoch {}: Training End      ####################'.format(epoch))\n",
    "\n",
    "        print()\n",
    "        print(\"#################### Epoch {}: Validation Start ####################\".format(epoch))\n",
    "\n",
    "        valid_loss, val_targets, val_outputs = valid(model, valid_dataloader)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "\n",
    "            #checkpoint = {\n",
    "                    #    'state_dict': model.state_dict(),\n",
    "                    #    'enc' : enc.get_params()\n",
    "                    #}\n",
    "\n",
    "            #save_ckp(checkpoint, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            num_not_improved = 0\n",
    "        else:\n",
    "            num_not_improved += 1\n",
    "            if num_not_improved >= patience:\n",
    "                print('Not improvement for more than:', num_not_improved)\n",
    "                break\n",
    "            \n",
    "        print(\"#################### Epoch {}: Validation End   ####################\".format(epoch))\n",
    "        print()\n",
    "\n",
    "    print(\"#################### Training finished     ####################\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Need to be train from scratch.\n",
      "\n",
      "#################### Epoch 1: Training Start    ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [07:41<00:00, 35.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Epoch 1: Training End      ####################\n",
      "\n",
      "#################### Epoch 1: Validation Start ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:37<00:00,  9.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.670940 \tValidation Loss: 0.634460\n",
      "Validation loss decreased (inf --> 0.634460).  Saving model ...\n",
      "#################### Epoch 1: Validation End   ####################\n",
      "\n",
      "\n",
      "#################### Epoch 2: Training Start    ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [07:46<00:00, 35.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Epoch 2: Training End      ####################\n",
      "\n",
      "#################### Epoch 2: Validation Start ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:35<00:00,  8.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.606649 \tValidation Loss: 0.582038\n",
      "Validation loss decreased (0.634460 --> 0.582038).  Saving model ...\n",
      "#################### Epoch 2: Validation End   ####################\n",
      "\n",
      "\n",
      "#################### Epoch 3: Training Start    ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [01:56<06:28, 38.80s/it]"
     ]
    }
   ],
   "source": [
    "print('No saved model found. Need to be train from scratch.')\n",
    "trained_model = train_model(EPOCHS, train_loader, val_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:45<00:00, 11.41s/it]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_labels , test_predictions_probs = valid(trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4385611116886139"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test_predictions = [[prob > threshold for prob in prob_list] for prob_list in test_predictions_probs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False],\n",
       " [False, False, False, False, False, False]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Affirm       0.00      0.00      0.00        28\n",
      "     Clarify       0.00      0.00      0.00        10\n",
      "    Disagree       0.00      0.00      0.00         2\n",
      "   Elaborate       0.00      0.00      0.00        22\n",
      "      Filler       0.00      0.00      0.00        12\n",
      "        None       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       122\n",
      "   macro avg       0.00      0.00      0.00       122\n",
      "weighted avg       0.00      0.00      0.00       122\n",
      " samples avg       0.00      0.00      0.00       122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay/EMAI/Ljublajna/NLP/ul-fri-nlp-course-project-processingbit/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nikolay/EMAI/Ljublajna/NLP/ul-fri-nlp-course-project-processingbit/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nikolay/EMAI/Ljublajna/NLP/ul-fri-nlp-course-project-processingbit/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nikolay/EMAI/Ljublajna/NLP/ul-fri-nlp-course-project-processingbit/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(test_labels, test_predictions))\n",
    "print('Precision:', precision_score(test_labels, test_predictions, average='weighted'))\n",
    "print('Recall:', recall_score(test_labels, test_predictions, average='weighted'))\n",
    "print('F1:', f1_score(test_labels, test_predictions, average='weighted'))\n",
    "\n",
    "report = classification_report(test_labels, test_predictions, target_names=enc.categories_[0])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
